---
title: "Introduction to $\bf{MultivarTV}"
author: "Brayan Ortiz"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
    toc: true
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\VignetteKeywords{R, C++, Armadillo, total variation, thin plate splines, denoising, piece-wise constant signals, signal processing}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r libsetup, include = FALSE, echo=FALSE}
library(plot3D)
library(fields)
library(MultivarTV)
# Towers function
towers <- function(x1,x2){
	n=length(x1)
	y = numeric(n)
	for (i in 1:n){ 
		y[i] = 1*(x1[i]>0.8)*1*(x2[i]>0.8)+0.5*1*(x1[i]>0.8)*1*(x2[i]<0.2)+1*1*(x1[i]<0.2)*1*(x2[i]<0.2)+0.5*1*(x1[i]<0.2)*1*(x2[i]>0.8)
	}
	return(y)
}

pcf <- function(x){
  if (x<0.1) return(0.5)
  else if (x>= 0.1 & x<0.6) return(3)
  else if (x>= 0.6 & x<0.8) return(0.5)
  else return(2)
}
pcwise <- function(vecx){
  y <- numeric(length(vecx))
  for (i in 1:length(vecx)){
    y[i] <- pcf(vecx[i])
  }
  return(y)
}
```

## Abstract

Total variation is a widely applicable regularization problem that is commonly used in signal and image denoising. We introduce the $\tt{R}$ package $\bf{MultivarTV}$, which is used for solving the multivariate total variation problem. Using an alternating direction method of multipliers algorithm (ADMM), we are able to solve problems large in sample size and number of features. 

## Introduction

To introduce total variation, we consider the univariate or one-dimensional case first. We begin by observing 
\[
y_i=f(x_i)+\epsilon_i,
\]
where $\mathbb{E}[\epsilon_i]=0$, $\mathbb{var}[\epsilon_i]=\sigma^2<\infty$ and $f\in \mathcal{F}$ (for $i=1,\ldots,N$). A total variation problem seeks to estimate $f$ by $\hat{f}$, such that
\[
\hat{f} = \min_{f\in\mathcal{F}} \frac{1}{N}\sum_{i=1}^N \left(y_i-f(x_i)\right)^2+\lambda P(f),
\]
where $P(f)=\int|f^{(1)}(t)|\partial t$ (i.e. the total variation norm). $\bf{MultivarTV}$ in the univariate setting uses a mesh based solution, which is described by Ortiz and Simon (2018). For a mesh based solution, we consider a set of $m$ points, $d_1,\ldots,d_m$ that need not have been observed and aim to estimate their value $\theta_j = f(d_j)$. Let $\theta_{(i)}= \theta_j$ such that $d_j\le x_i<d_{j+1}$ (nearest neighbor). The mesh based solution to the univariate problem approximates $f(x_1),\ldots,f(x_N)$ by the values $\hat{\theta}=(\hat{\theta}_{(1)},\ldots,\hat{\theta}_{(N)})$, where:
\[
\hat{\theta} = \min_{\theta\in \mathbb{R}^m} \frac{1}{N}\sum_{i=1}^N \left(y_i-\theta_{(i)}\right) + \lambda \sum_{j=1}^m \left|\theta_{j+1}-\theta_j\right|.
\]
Ortiz and Simon (2018) show that choosing $m\ge\sqrt{N}$ (with regular spacing) is enough for statistical optimality of the solution $\hat{\theta}$. Since the optimization problem encourages adjacent points $\theta$ to be the same, we draw piecewise-constant fits as our solution. To begin our demonstration, we generate some data from a piecewise constant function:

```{r datagen}
set.seed(123)
N <- 100
x <- matrix(runif(N),ncol=1)
y <- matrix(pcwise(x) + rnorm(N,0,0.1),ncol=1)
```

To fit a total variation solution to this data, we need only use the $\tt{mvtv}$ function, which by default will perform 5-fold validation and stores the solution path for each $\lambda$. Let $m = 20$ for this problem:

```{r mvtv1, echo=FALSE}
set.seed(123) # Setting a seed for cross-validation procedure
m <- matrix(20,ncol=1)
fit <- mvtv(x,y,m,verbose=FALSE) # Verbose = FALSE to suppress algorithm details
```

We include an S3 generic $\tt{plot}$ function with additional flags. By default, we plot the predicted surface for the best cross-validated model and overlay observed data:

```{r fig1, fig.cap = "Total variation solution for piecewise constant function at best cross-validated model. "}
plot(fit)
```

The $\tt{plot}$ function can also be used to see fits at other values of $\lambda$:

```{r fig2, fig.cap = "Total variation solution for piecewise constant function at another solution."}
plot(fit, lambda = 2.0)
```

Aside from the number of knots, the user can also define the mesh itself. Note that by setting $m=N$ and $d_1=x_1,\dlots,d_N=x_N$, we return the fused lasso solution (tibs): 

```{r mvtv_fl, echo=FALSE}
set.seed(123) # Setting a seed for cross-validation procedure
m <- matrix(N,ncol=1)
mesh <- x
fl_mvtv <- mvtv(x,y,m,mesh = mesh, verbose=FALSE) # Verbose = FALSE to suppress algorithm details
plot(fl_mvtv)

library(genlasso)
fl_genlasso <- fusedlasso1d(y)
plot(fl_genlasso)
```


## $\bf{MultivarTV}$ for Multivariate Data

For multivariate data, the total variation problem becomes difficult, which can be explained by seeing what changes in the bivariate setting. A total variation problem seeks to constrain the amount a function changes or varies in it's first derivative, which in the univariate setting means setting
\[
P(f) = \int |f^{(1)}(x)|\partial x < M,
\]
which we approximate using first differences as $\sum_{j=1}^m \left|\theta_{j+1}-\theta_j\right|$ in our problem. In the bivariate setting, a function $f(x_1, x_2)$ has three first derivatives: $\frac{\partial}{\partial x_1}$, $\frac{\partial}{\partial x_2}$, and $\frac{\partial}{\partial x_1\partial x_2}$. Hence, our penalty parameter becomes
\[
P(f) = \int \left|\frac{\partial}{\partial x_1}  f(x_1, x_2) \right|\partial x_1\partial x_2 +\int \left|\frac{\partial}{\partial x_2}  f(x_1, x_2) \right|\partial x_1\partial x_2+\int \left|\frac{\partial}{\partial x_1 \partial x_2}  f(x_1, x_2) \right|\partial x_1\partial x_2.
\]
$\bf{MultivarTV}$ continues to approximate $P(f)$ using first differences. First, note that for the univariate problem we can rewrite $\sum_{j=1}^m \left|\theta_{j+1}-\theta_j\right|$ as $\|D\theta\|_1$ using the $\ell_1$-norm and first difference matrix 
\[
D = \begin{bmatrix}
  -1 & 1 & 0 & \ldots & 0 & 0 \\
  0 & -1 & 1 & \ldots & 0 & 0 \\
  \vdots  & \vdots & \vdots& \ddots &  \vdots &  \vdots \\
    0 & 0 & 0 & ... & -1 & 1 
    \end{bmatrix}.
\]
For $x_{1,1},\ldots,x_{1,N}$, we create a mesh $d_{1,1},\ldots,d_{1,m_1}$ that contains all of $x_1$ (and do the same for $x_2$). We merge $d_1$ and $d_2$ into a lattice such that 
\[
\theta = \begin{bmatrix}
  f(d_{11},d_{21}) & f(d_{12},d_{21})  & \ldots  & f(d_{1m_1},d_{21}) \\
  f(d_{11},d_{22}) & f(d_{21},d_{22}) & \ldots & f(d_{1m_1},d_{22})  \\
   \vdots &  \ddots &  \vdots &  \vdots \\
     f(d_{11},d_{2m_2}) & f(d_{12},d_{2m_2}) & ... &  f(d_{1m_1},d_{2m_2}) 
    \end{bmatrix}.
\]
We can approximate 
### Towers Function

We want to fit any multivariate surface as the solution to a total variation problem. One surface that we can use for demonstration is one that resembles four towers on a plain. In Figure 1, we plot the towers as a mesh and overlay points generated from the towers function with noise. 

```{r ,eval=FALSE}
# Note that we use gen_mesh() in MultivarTV package to generate function.
dat <- seq(0+0.0001,1-0.0001,length.out = 5)
mat <- cbind(dat,dat)
m <- matrix(rep(30,2),ncol=1)
dataMesh <- gen_mesh(mat,m,NULL )
y <- towers(dataMesh[,1],dataMesh[,2])
set.seed(117)
ynoisy <- y + rnorm(length(y),0,0.1)
```


```{r fig1, echo=FALSE, fig.cap = "Figure 1. Plot of N=100 points drawn from Towers function (drawn as mesh) with noise.", fig.width=4, fig.height = 4}
x1 <- seq(0,1,length.out=40); x2 <- x1
x1x2 <- expand.grid(x1,x2)
z <- matrix(towers(x1x2[,1],x1x2[,2]),nrow=40,ncol = 40)
#y <- outer(x1,x2,towers)
set.seed(117)
z1 <- runif(100)
z2 <- runif(100)
z3 <- towers(z1,z2)
ynoisy <- z3 + rnorm(length(z3),0,0.5)

scatter3D(z1,z2,ynoisy,theta=30,phi=30,xlab="x1",ylab="x2",zlab="y",cex=1,pch=20,
          surf= list(x = x1,y = x2,z = z,facets=NA,fit = z3))

```


The noisy towers can be fit well by a total variation solution. In this example, we will also compare the total variation fit against a thin plate spline. Based on Figure 2, we indeed get a jagged sombrero for our total variation solution. In Figure 3, we see the thin plate spline solution, which is much more smooth and perhaps introduces too much wiggliness along the ridges of the sombrero. When we increase the noise (from $\sigma=0.1$ to $\sigma=0.5$), thin plate splines behave similarly as before (Figure 5), while the total variation solution has more regularization (Figure 4). This contrast illustrates how a denoising solution will tend to behave in the presence of large amounts of noise, i.e. more regularity will be introduced in the solution. However, this does not mean that the fit is necessarily better or worse. Next, we investigate how the total variation solution compares to the thin plate spline in simulation. 


```{r figure2, echo=TRUE, fig.cap="Figure 2. Total variation solution for noisy sombrero." , fig.width=5, fig.height = 7}
set.seed(117)
mym <- matrix(rep(sqrt(length(ynoisy)),2),ncol=1)
data <- cbind(z1,z2)
tvmod <- mvtv(data,ynoisy,mym,verbose=FALSE)
plot(tvmod,adddata = TRUE)
```


```{r figure3,echo=TRUE, fig.cap="Figure 3. Thin plate spline solution for noisy sombrero." , fig.width=5, fig.height = 7}
fit <- Tps(data,ynoisy)
out.p <- predictSurface(fit, xy = c(1,2))
plot.surface(out.p, type="p")
```


```{r figure4, echo=TRUE, fig.cap="Figure 4. Total variation solution for noisier sombrero.", fig.width=5, fig.height = 7}
set.seed(117)
ynoisy2 <- z3 + rnorm(length(z3),0,0.5)

set.seed(117)
tvmod2 <- mvtv(data,ynoisy2,mym,verbose=FALSE)
plot(tvmod,adddata = TRUE)
```


```{r figure5,echo=TRUE, fig.cap="Figure 5. Thin plate spline solution for noisier sombrero.", fig.width=5, fig.height = 7}
fit2 <- Tps(data,ynoisy2)
out.p2 <- predictSurface(fit2, xy = c(1,2))
plot.surface(out.p2, type="p")
```

## Conclusions
